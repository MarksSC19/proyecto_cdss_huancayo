{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Entrenamiento y Evaluación de Modelos\n",
                "\n",
                "**Objetivo:** Entrenar y comparar múltiples algoritmos de clasificación para seleccionar el modelo con el mejor rendimiento para nuestro problema de diagnóstico diferencial. Utilizaremos validación cruzada rigurosa y manejaremos el desbalance de clases identificado en el EDA."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.1. Carga de Datos Procesados y Librerías"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'xgboost'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, VotingClassifier\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msvm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Manejo de Desbalance\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline \u001b[38;5;28;01mas\u001b[39;00m ImbPipeline\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xgboost'"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "import os\n",
                "\n",
                "# Librerías de Modelado\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
                "from sklearn.svm import SVC\n",
                "import xgboost as xgb\n",
                "\n",
                "# Manejo de Desbalance\n",
                "from imblearn.pipeline import Pipeline as ImbPipeline\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "# Evaluación\n",
                "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
                "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, cohen_kappa_score\n",
                "\n",
                "# Rutas\n",
                "PROCESSED_DATA_DIR = \"../data/processed/\"\n",
                "MODELS_DIR = \"../models/\"\n",
                "\n",
                "# Cargar datos\n",
                "X_train = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, 'X_train.csv'))\n",
                "X_test = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, 'X_test.csv'))\n",
                "y_train = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, 'y_train.csv')).values.ravel()\n",
                "y_test = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, 'y_test.csv')).values.ravel()\n",
                "\n",
                "print('Datos cargados:')\n",
                "print(f'X_train: {X_train.shape}')\n",
                "print(f'y_train: {y_train.shape}')\n",
                "print(f'X_test: {X_test.shape}')\n",
                "print(f'y_test: {y_test.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.2. Definición de Modelos y Pipeline con SMOTE\n",
                "\n",
                "Para cada clasificador, crearemos un pipeline de `imbalanced-learn`. Este pipeline primero aplicará SMOTE para sobremuestrear las clases minoritarias y luego entrenará el clasificador. Esto se hace de forma segura dentro de cada pliegue de la validación cruzada para evitar la fuga de datos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definir los modelos base\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42),\n",
                "    'Random Forest': RandomForestClassifier(random_state=42),\n",
                "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
                "    'SVM': SVC(probability=True, random_state=42) # probability=True es necesario para VotingClassifier y AUC\n",
                "}\n",
                "\n",
                "# Crear un pipeline con SMOTE para cada modelo\n",
                "pipelines = {\n",
                "    name: ImbPipeline(steps=[('smote', SMOTE(random_state=42)), ('classifier', model)]) \n",
                "    for name, model in models.items()\n",
                "}\n",
                "\n",
                "# Añadir un modelo de ensamble (Voting Classifier)\n",
                "# Usamos los clasificadores ya definidos (sin SMOTE aquí, ya que el pipeline se encargará de ello)\n",
                "clf1 = models['Logistic Regression']\n",
                "clf2 = models['Random Forest']\n",
                "clf3 = models['XGBoost']\n",
                "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('xgb', clf3)], voting='soft')\n",
                "pipelines['Ensemble (Voting)'] = ImbPipeline(steps=[('smote', SMOTE(random_state=42)), ('classifier', eclf1)])\n",
                "\n",
                "print(\"Pipelines de modelos creados:\")\n",
                "print(list(pipelines.keys()))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.3. Evaluación con Validación Cruzada\n",
                "\n",
                "Utilizaremos `StratifiedKFold` con 10 pliegues para evaluar el rendimiento de cada pipeline. Mediremos múltiples métricas para obtener una visión completa del rendimiento de cada modelo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configurar la validación cruzada\n",
                "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
                "\n",
                "# Métricas a evaluar\n",
                "scoring_metrics = ['accuracy', 'balanced_accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted', 'roc_auc_ovr']\n",
                "\n",
                "results = {}\n",
                "\n",
                "for name, pipeline in pipelines.items():\n",
                "    print(f'Evaluando {name}...')\n",
                "    # Realizar validación cruzada\n",
                "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring_metrics, n_jobs=-1)\n",
                "    results[name] = {metric: cv_results[f'test_{metric}'] for metric in scoring_metrics}\n",
                "    print(f'{name} - Balanced Accuracy: {np.mean(cv_results['test_balanced_accuracy']):.4f} +/- {np.std(cv_results['test_balanced_accuracy']):.4f}')\n",
                "\n",
                "print(\"\\nEvaluación completada.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.4. Comparación de Modelos\n",
                "\n",
                "Visualizaremos los resultados de la validación cruzada para comparar los modelos y seleccionar el mejor para el entrenamiento final."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convertir resultados a un DataFrame para fácil visualización\n",
                "results_df = pd.DataFrame.from_dict({(i,j): results[i][j].mean() \n",
                "                                     for i in results.keys() \n",
                "                                     for j in results[i].keys()},\n",
                "                                    orient='index', columns=['Score']).unstack()\n",
                "\n",
                "results_df.columns = results_df.columns.droplevel()\n",
                "results_df = results_df.rename_axis(None, axis=1).reset_index().rename(columns={'index': 'Model'})\n",
                "\n",
                "print(\"\\nRendimiento promedio en Validación Cruzada (k=10):\")\n",
                "display(results_df.sort_values(by='balanced_accuracy', ascending=False))\n",
                "\n",
                "# Gráfico de comparación\n",
                "results_df.set_index('Model').plot(kind='bar', figsize=(18, 8), colormap='viridis')\n",
                "plt.title('Comparación de Modelos - Métricas de Validación Cruzada', fontsize=16)\n",
                "plt.ylabel('Score', fontsize=12)\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.legend(title='Métricas', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
                "plt.grid(axis='y', linestyle='--')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.5. Entrenamiento del Modelo Final y Evaluación en Test\n",
                "\n",
                "Basado en los resultados (generalmente XGBoost o Random Forest son buenos candidatos), seleccionamos el mejor modelo, lo entrenamos en **todo** el conjunto de entrenamiento y lo evaluamos en el conjunto de prueba, que el modelo no ha visto nunca."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Seleccionar el mejor modelo (ej. XGBoost basado en resultados típicos)\n",
                "best_model_name = 'XGBoost'\n",
                "final_pipeline = pipelines[best_model_name]\n",
                "\n",
                "print(f'Entrenando el modelo final: {best_model_name}...')\n",
                "final_pipeline.fit(X_train, y_train)\n",
                "\n",
                "# Predicciones en el conjunto de prueba\n",
                "y_pred = final_pipeline.predict(X_test)\n",
                "\n",
                "# Métricas de evaluación finales\n",
                "diagnostico_map = {0: 'DM2', 1: 'EDA', 2: 'HTA', 3: 'IRA'}\n",
                "target_names = [diagnostico_map[i] for i in sorted(diagnostico_map.keys())]\n",
                "\n",
                "print(\"--- Reporte de Clasificación en Conjunto de Prueba ---\")\n",
                "print(classification_report(y_test, y_pred, target_names=target_names))\n",
                "\n",
                "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred):.4f}\")\n",
                "print(f\"Cohen's Kappa: {cohen_kappa_score(y_test, y_pred):.4f}\")\n",
                "\n",
                "# Matriz de Confusión\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
                "plt.title('Matriz de Confusión en Conjunto de Prueba', fontsize=16)\n",
                "plt.xlabel('Predicción', fontsize=12)\n",
                "plt.ylabel('Real', fontsize=12)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.6. Guardar el Modelo Final Entrenado\n",
                "\n",
                "Guardamos el pipeline completo (SMOTE + clasificador) para poder usarlo directamente en la aplicación de Streamlit y en el notebook de interpretabilidad."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_model_path = os.path.join(MODELS_DIR, 'final_model.pkl')\n",
                "joblib.dump(final_pipeline, final_model_path)\n",
                "\n",
                "print(f'Modelo final guardado en: {final_model_path}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
